{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "055a464c",
   "metadata": {},
   "source": [
    "# Deploying an Amazon Comprehend Model with SageMaker Pipelines\n",
    "\n",
    "This example notebook showcases how you can deploy a custom text classification using Amazon Comprehend and SageMaker Pipelines.\n",
    "\n",
    "Before you start make sure that your SageMaker Execution Role has the following policies:\n",
    "\n",
    "- `ComprehendFullAccess`\n",
    "- `AmazonSageMakerFullAccess`\n",
    "- `AWSLambda_FullAccess`\n",
    "\n",
    "Your SageMaker Execution Role should have access to S3 already. If not you can add the S3 full access policy.\n",
    "You will also need to add `iam:passRole` as an inline policy."
   ]
  },
  {
   "cell_type": "raw",
   "id": "26c8e731",
   "metadata": {},
   "source": [
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Action\": [\n",
    "                \"iam:PassRole\"\n",
    "            ],\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Resource\": \"*\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4212cb",
   "metadata": {},
   "source": [
    "Finally, you will need the following trust policies."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1caad77",
   "metadata": {},
   "source": [
    "{\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": [\n",
    "    {\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Principal\": {\n",
    "        \"Service\": [\n",
    "          \"sagemaker.amazonaws.com\",\n",
    "          \"s3.amazonaws.com\",\n",
    "          \"comprehend.amazonaws.com\",\n",
    "          \"lambda.amazonaws.com\"\n",
    "        ]\n",
    "      },\n",
    "      \"Action\": \"sts:AssumeRole\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8eaf82",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "First, we are going to import the SageMaker SDK and set some default variables such as the `role` for permissioned execution and the `default_bucket` to store model artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01cd3107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2021.11.0-py3-none-any.whl (25 kB)\n",
      "Collecting fsspec==2021.11.0\n",
      "  Downloading fsspec-2021.11.0-py3-none-any.whl (132 kB)\n",
      "     |████████████████████████████████| 132 kB 18.5 MB/s            \n",
      "\u001b[?25hCollecting aiohttp>=3.7.1\n",
      "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "     |████████████████████████████████| 1.1 MB 34.5 MB/s            \n",
      "\u001b[?25hCollecting aiobotocore~=1.4.1\n",
      "  Downloading aiobotocore-1.4.2.tar.gz (52 kB)\n",
      "     |████████████████████████████████| 52 kB 2.5 MB/s             \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting botocore<1.20.107,>=1.20.106\n",
      "  Downloading botocore-1.20.106-py2.py3-none-any.whl (7.7 MB)\n",
      "     |████████████████████████████████| 7.7 MB 70.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.10.10 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from aiobotocore~=1.4.1->s3fs) (1.12.1)\n",
      "Collecting aioitertools>=0.5.1\n",
      "  Downloading aioitertools-0.8.0-py3-none-any.whl (21 kB)\n",
      "Collecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "     |████████████████████████████████| 271 kB 45.2 MB/s            \n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
      "     |████████████████████████████████| 192 kB 62.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from aiohttp>=3.7.1->s3fs) (3.10.0.2)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from aiohttp>=3.7.1->s3fs) (2.0.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from aiohttp>=3.7.1->s3fs) (21.2.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
      "     |████████████████████████████████| 160 kB 66.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from botocore<1.20.107,>=1.20.106->aiobotocore~=1.4.1->s3fs) (1.26.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from botocore<1.20.107,>=1.20.106->aiobotocore~=1.4.1->s3fs) (2.8.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from botocore<1.20.107,>=1.20.106->aiobotocore~=1.4.1->s3fs) (0.10.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp>=3.7.1->s3fs) (3.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.107,>=1.20.106->aiobotocore~=1.4.1->s3fs) (1.16.0)\n",
      "Building wheels for collected packages: aiobotocore\n",
      "  Building wheel for aiobotocore (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for aiobotocore: filename=aiobotocore-1.4.2-py3-none-any.whl size=49926 sha256=10f9aa43df01c000a8dfa57c55c1b9bdb315ee9428b52afe5c556cb0968eb52a\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/33/e7/d9/b297a9aa9c43d56bc2463e6e2771655ff638f30b30f0b61fcb\n",
      "Successfully built aiobotocore\n",
      "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, botocore, aioitertools, aiohttp, fsspec, aiobotocore, s3fs\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.23.5\n",
      "    Uninstalling botocore-1.23.5:\n",
      "      Successfully uninstalled botocore-1.23.5\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 0.8.3\n",
      "    Uninstalling fsspec-0.8.3:\n",
      "      Successfully uninstalled fsspec-0.8.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "boto3 1.20.5 requires botocore<1.24.0,>=1.23.5, but you have botocore 1.20.106 which is incompatible.\n",
      "awscli 1.22.5 requires botocore==1.23.5, but you have botocore 1.20.106 which is incompatible.\u001b[0m\n",
      "Successfully installed aiobotocore-1.4.2 aiohttp-3.8.1 aioitertools-0.8.0 aiosignal-1.2.0 async-timeout-4.0.1 asynctest-0.13.0 botocore-1.23.2 frozenlist-1.2.0 fsspec-2021.11.0 multidict-5.2.0 s3fs-2021.11.0 yarl-1.7.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "72798f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fc98416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.lambda_step import (\n",
    "    LambdaStep,\n",
    "    LambdaOutput,\n",
    "    LambdaOutputTypeEnum,\n",
    ")\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "role_arn = sagemaker.get_execution_role()\n",
    "default_bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8882a53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy: s3://aws-ml-blog/artifacts/comprehend-custom-classification/comprehend-train.csv to s3://sagemaker-eu-west-1-727118255515/comprehend-train.csv\n",
      "copy: s3://aws-ml-blog/artifacts/comprehend-custom-classification/comprehend-test.csv to s3://sagemaker-eu-west-1-727118255515/comprehend-test.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://aws-ml-blog/artifacts/comprehend-custom-classification/comprehend-train.csv s3://$default_bucket/\n",
    "!aws s3 cp s3://aws-ml-blog/artifacts/comprehend-custom-classification/comprehend-test.csv s3://$default_bucket/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4482cae5",
   "metadata": {},
   "source": [
    "Next, we define parameters that can be set for the execution of the pipeline. They serve as variables. We define the following:\n",
    "\n",
    "- `ProcessingInstanceType`: The number of processing instances to use for the execution of the pipeline\n",
    "- `TrainData`: Location of the training data in S3\n",
    "- `TestData`: Location of the test data in S3\n",
    "- `RoleArn`: ARN (Amazon Resource Name) of the role used for pipeline execution\n",
    "- `ModelOutput`: Location of the target S3 path for the Amazon Comprehend model artifact\n",
    "\n",
    "Amazon Comprehend creates its own validation set when training, so there is no need to provide one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b183fd31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCIENCE_AND_MATHEMATICS</td>\n",
       "      <td>What is an \\imaginary number\\\"? \\n What is an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTERTAINMENT_AND_MUSIC</td>\n",
       "      <td>What's the cheapest source for ordering DVDs f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BUSINESS_AND_FINANCE</td>\n",
       "      <td>If I lose lots of money in stock in one year&amp;#...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCIENCE_AND_MATHEMATICS</td>\n",
       "      <td>When can a common man fly to moon? \\n My realt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SOCIETY_AND_CULTURE</td>\n",
       "      <td>When do you use a semicolon instead of a colon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99986</th>\n",
       "      <td>POLITICS_AND_GOVERNMENT</td>\n",
       "      <td>I need help reporting a person who is working ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99987</th>\n",
       "      <td>ENTERTAINMENT_AND_MUSIC</td>\n",
       "      <td>What happened to the rebate for 'Friends' seas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99988</th>\n",
       "      <td>POLITICS_AND_GOVERNMENT</td>\n",
       "      <td>Are terrorists allowed to edit \\factual inform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99989</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>do u think that STEVE NASH deserves the MVP???...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99990</th>\n",
       "      <td>EDUCATION_AND_REFERENCE</td>\n",
       "      <td>Hi everybody i need a hindi translator in duba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99991 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0  \\\n",
       "0      SCIENCE_AND_MATHEMATICS   \n",
       "1      ENTERTAINMENT_AND_MUSIC   \n",
       "2         BUSINESS_AND_FINANCE   \n",
       "3      SCIENCE_AND_MATHEMATICS   \n",
       "4          SOCIETY_AND_CULTURE   \n",
       "...                        ...   \n",
       "99986  POLITICS_AND_GOVERNMENT   \n",
       "99987  ENTERTAINMENT_AND_MUSIC   \n",
       "99988  POLITICS_AND_GOVERNMENT   \n",
       "99989                   SPORTS   \n",
       "99990  EDUCATION_AND_REFERENCE   \n",
       "\n",
       "                                                       1  \n",
       "0      What is an \\imaginary number\\\"? \\n What is an ...  \n",
       "1      What's the cheapest source for ordering DVDs f...  \n",
       "2      If I lose lots of money in stock in one year&#...  \n",
       "3      When can a common man fly to moon? \\n My realt...  \n",
       "4      When do you use a semicolon instead of a colon...  \n",
       "...                                                  ...  \n",
       "99986  I need help reporting a person who is working ...  \n",
       "99987  What happened to the rebate for 'Friends' seas...  \n",
       "99988  Are terrorists allowed to edit \\factual inform...  \n",
       "99989  do u think that STEVE NASH deserves the MVP???...  \n",
       "99990  Hi everybody i need a hindi translator in duba...  \n",
       "\n",
       "[99991 rows x 2 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting train and test files\n",
    "import pandas as pd\n",
    "\n",
    "trainFrame = pd.read_csv(\n",
    "    \"s3://aws-ml-blog/artifacts/comprehend-custom-classification/comprehend-train.csv\",\n",
    "    header=None,\n",
    ")\n",
    "trainFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "21eed630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Whch is most popular website for indians? \\n w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What jobs am I eligible for&amp;#44; when I have a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did Johnny Depp based his Willy Wonka persona ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do I get a buyer to leave me feedback on e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Do you believe in abortion? \\n Are you pro-lif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>What is the role of religion in society? \\n At...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>how do i retrieve info. on a particular murder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Is there a way to keep my company from blockin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Book Smarts or Street Smarts? \\n Okie. I'm jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>which muscle group should i work out to get st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0\n",
       "0   Whch is most popular website for indians? \\n w...\n",
       "1   What jobs am I eligible for&#44; when I have a...\n",
       "2   Did Johnny Depp based his Willy Wonka persona ...\n",
       "3   How do I get a buyer to leave me feedback on e...\n",
       "4   Do you believe in abortion? \\n Are you pro-lif...\n",
       "..                                                ...\n",
       "95  What is the role of religion in society? \\n At...\n",
       "96  how do i retrieve info. on a particular murder...\n",
       "97  Is there a way to keep my company from blockin...\n",
       "98  Book Smarts or Street Smarts? \\n Okie. I'm jus...\n",
       "99  which muscle group should i work out to get st...\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFrame = pd.read_csv(\n",
    "    \"s3://aws-ml-blog/artifacts/comprehend-custom-classification/comprehend-test.csv\",\n",
    "    header=None,\n",
    ")\n",
    "testFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "44d93ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\", default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "\n",
    "input_train = ParameterString(\n",
    "    name=\"TrainData\",\n",
    "    default_value=f\"s3://{default_bucket}/comprehend-train.csv\",\n",
    ")\n",
    "\n",
    "input_test = ParameterString(\n",
    "    name=\"TestData\",\n",
    "    default_value=f\"s3://{default_bucket}/comprehend-test.csv\",\n",
    ")\n",
    "\n",
    "iam_role_arn = ParameterString(\n",
    "    name=\"RoleArn\",\n",
    "    default_value=role_arn,\n",
    ")\n",
    "\n",
    "model_output = ParameterString(name=\"ModelOutput\", default_value=f\"s3://{default_bucket}/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db70604",
   "metadata": {},
   "source": [
    "We use [SKLearnProcessor](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html#sagemaker.sklearn.processing.SKLearnProcessor) to run Python scripts to train, and deploy Amazon Comprehend models using `boto3`. In the next chunk, we instantiate an instance of `SKLearnProcessor` that we use in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2b998171",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"comprehend-process\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role_arn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05886564",
   "metadata": {},
   "source": [
    "The first Amazon SageMaker [ProcessingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html?highlight=ProcessingStep#sagemaker.workflow.steps.ProcessingStep) provides a containerized execution environment to run the `prepare_data.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "448c6d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = ProcessingStep(\n",
    "    name=\"ComprehendProcess\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=input_train, destination=\"/opt/ml/processing/input_train\"),\n",
    "        ProcessingInput(source=input_test, destination=\"/opt/ml/processing/input_test\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    code=\"prepare_data.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42311799",
   "metadata": {},
   "source": [
    "The second Amazon SageMaker processing step trains the Amazon Comprehend model by running `train_eval_comprehend.py`. Amazon Comprehend automatically evaluates the performance on an evaluation set. We will use that score as a condition for deploying the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9800e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_report = PropertyFile(\n",
    "    name=\"ComprehendEvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d2221b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehend_train_and_eval = ProcessingStep(\n",
    "    name=\"ComprehendTrainAndEval\",\n",
    "    processor=sklearn_processor,\n",
    "    job_arguments=[\n",
    "        \"--train-input-file\",\n",
    "        preprocess.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "        \"--train-output-path\",\n",
    "        model_output,\n",
    "        \"--iam-role-arn\",\n",
    "        role_arn,\n",
    "    ],\n",
    "    code=\"train_eval_comprehend.py\",\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "        ProcessingOutput(output_name=\"arn\", source=\"/opt/ml/processing/arn\"),\n",
    "    ],\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b7a6a2",
   "metadata": {},
   "source": [
    "The third Amazon SageMaker processing step deploys the Amazon Comprehend model running `deploy_comprehend.py`. If the Accuracy reported after training is lower than a certain threshold, this step does not run and the pipeline stops here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "93dc2a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_deploy_model = ProcessingStep(\n",
    "    name=\"ComprehendDeploy\",\n",
    "    processor=sklearn_processor,\n",
    "    job_arguments=[\n",
    "        \"--arn-path\",\n",
    "        comprehend_train_and_eval.properties.ProcessingOutputConfig.Outputs[\"arn\"].S3Output.S3Uri,\n",
    "    ],\n",
    "    code=\"deploy_comprehend.py\",\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"endpoint_arn\", source=\"/opt/ml/processing/endpoint_arn\")\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7e305e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.workflow.properties.Properties at 0x7efec5956dd0>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comprehend_train_and_eval.properties.ProcessingOutputConfig.Outputs[\"arn\"].S3Output.S3Uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9e80b06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "cond_lte = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=\"ComprehendTrainAndEval\",\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"Accuracy\",\n",
    "    ),\n",
    "    right=0.65,\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=\"ComprehendAccuracyCondition\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_deploy_model],\n",
    "    else_steps=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f57ffdf",
   "metadata": {},
   "source": [
    "Finally, the deployed model can be used for inference. At this stage we use [AWS Lambda](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.lambda_step.LambdaStep) to call the Amazon Comprehend endpoint with the text of our choice.\n",
    "\n",
    "A role is needed to create the Lambda function. We will use a helper function, `iam_helper.py` from the [Lambda Step example](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-pipelines/tabular/lambda-step/iam_helper.py) to create the role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5390a4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ARN from existing role: test-comprehend-lambda-role\n"
     ]
    }
   ],
   "source": [
    "from iam_helper import create_lambda_role\n",
    "\n",
    "lambda_role = create_lambda_role(\"test-comprehend-lambda-role\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "44bc22bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = (\n",
    "    \"Italian EBU Member RAI has won the 65th Eurovision Song Contest with the song \"\n",
    "    + \"Zitti e buoni performed by Måneskin. It's the 3rd win for Italy who last triumphed in 1990. \"\n",
    "    + \"26 countries took part in the Grand Final of the world’s largest live music event, \"\n",
    "    + \"hosted by Dutch EBU Members NPO, NOS and AVROTROS on Saturday 22 May in Rotterdam. \"\n",
    "    + \"Måneskin wrote the winning song which finished the night with 524 points, 25 points \"\n",
    "    + \"ahead of 2nd placed France represented by Barbara Pravi singing Voila. Switzerland’s Gjon’s Tears with Tout l’Univers finished in third place.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fa3b9acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Lambda Step\n",
    "function_name = \"sagemaker-lambda-step-endpoint-test\"\n",
    "\n",
    "# Lambda helper class can be used to create the Lambda function\n",
    "func = Lambda(\n",
    "    function_name=function_name,\n",
    "    execution_role_arn=lambda_role,\n",
    "    script=\"test_comprehend_lambda.py\",\n",
    "    handler=\"test_comprehend_lambda.lambda_handler\",\n",
    ")\n",
    "\n",
    "test_endpoint = LambdaStep(\n",
    "    name=\"LambdaStep\",\n",
    "    lambda_func=func,\n",
    "    inputs={\n",
    "        \"endpoint_arn_path\": step_deploy_model.properties.ProcessingOutputConfig.Outputs[\n",
    "            \"endpoint_arn\"\n",
    "        ].S3Output.S3Uri,\n",
    "        \"text\": example_text,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "eda34689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.workflow.properties.Properties at 0x7efec46414d0>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_deploy_model.properties.ProcessingOutputConfig.Outputs[\"endpoint_arn\"].S3Output.S3Uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5d5b0bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline_name = \"ComprehendPipeline\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_type,\n",
    "        processing_instance_count,\n",
    "        input_train,\n",
    "        input_test,\n",
    "        iam_role_arn,\n",
    "        model_output,\n",
    "    ],\n",
    "    steps=[preprocess, comprehend_train_and_eval, step_cond, test_endpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801b71bc",
   "metadata": {},
   "source": [
    "Once the pipeline is successfully defined, we can start the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ab6fd44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:eu-west-1:727118255515:pipeline/comprehendpipeline',\n",
       " 'ResponseMetadata': {'RequestId': '7f80ea22-ed3f-4a67-8844-12f2fb6566ac',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '7f80ea22-ed3f-4a67-8844-12f2fb6566ac',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '86',\n",
       "   'date': 'Thu, 25 Nov 2021 16:12:09 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "43ceece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529e1a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f756e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5735690",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec75db41",
   "metadata": {},
   "source": [
    "In this notebook we have seen how to create a SageMaker Pipeline to train an Amazon Comprehend Custom Classifier on your own dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1904a18",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a96d8b50",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'boto3' has no attribute 'delete_endpoint'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4d9f2e498fab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mboto3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_deploy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcessingOutputConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"arn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'boto3' has no attribute 'delete_endpoint'"
     ]
    }
   ],
   "source": [
    "pipeline.delete()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "sagemaker-examples",
   "language": "python",
   "name": "sagemaker-examples"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
