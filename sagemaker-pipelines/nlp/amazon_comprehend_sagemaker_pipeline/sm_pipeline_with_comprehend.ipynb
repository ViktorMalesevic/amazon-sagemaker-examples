{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b94b7b30",
   "metadata": {},
   "source": [
    "# Deploying an Amazon Comprehend Model with SageMaker Pipelines\n",
    "\n",
    "This example notebook showcases how you can deploy a custom text classification using Amazon Comprehend and SageMaker Pipelines.\n",
    "\n",
    "Before you start make sure that your SageMaker Execution Role has the following policies:\n",
    "\n",
    "- `ComprehendFullAccess`\n",
    "- `AmazonSageMakerFullAccess`\n",
    "- `AWSLambda_FullAccess`\n",
    "\n",
    "Your SageMaker Execution Role should have access to S3 already. If not you can add the S3 full access policy.\n",
    "You will also need to add `iam:passRole` as an inline policy."
   ]
  },
  {
   "cell_type": "raw",
   "id": "56798a00",
   "metadata": {},
   "source": [
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Action\": [\n",
    "                \"iam:PassRole\"\n",
    "            ],\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Resource\": \"*\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90028c56",
   "metadata": {},
   "source": [
    "Finally, you will need the following trust policies."
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d577110",
   "metadata": {},
   "source": [
    "{\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": [\n",
    "    {\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Principal\": {\n",
    "        \"Service\": [\n",
    "          \"sagemaker.amazonaws.com\",\n",
    "          \"s3.amazonaws.com\",\n",
    "          \"comprehend.amazonaws.com\",\n",
    "          \"lambda.amazonaws.com\"\n",
    "        ]\n",
    "      },\n",
    "      \"Action\": \"sts:AssumeRole\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c74fa99",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "First, we are going to import the SageMaker SDK and set some default variables such as the `role` for permissioned execution and the `default_bucket` to store model artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ee4b18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2021.11.0-py3-none-any.whl (25 kB)\n",
      "Collecting fsspec==2021.11.0\n",
      "  Downloading fsspec-2021.11.0-py3-none-any.whl (132 kB)\n",
      "     |████████████████████████████████| 132 kB 18.5 MB/s            \n",
      "\u001b[?25hCollecting aiohttp>=3.7.1\n",
      "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "     |████████████████████████████████| 1.1 MB 34.5 MB/s            \n",
      "\u001b[?25hCollecting aiobotocore~=1.4.1\n",
      "  Downloading aiobotocore-1.4.2.tar.gz (52 kB)\n",
      "     |████████████████████████████████| 52 kB 2.5 MB/s             \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting botocore<1.20.107,>=1.20.106\n",
      "  Downloading botocore-1.20.106-py2.py3-none-any.whl (7.7 MB)\n",
      "     |████████████████████████████████| 7.7 MB 70.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.10.10 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from aiobotocore~=1.4.1->s3fs) (1.12.1)\n",
      "Collecting aioitertools>=0.5.1\n",
      "  Downloading aioitertools-0.8.0-py3-none-any.whl (21 kB)\n",
      "Collecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "     |████████████████████████████████| 271 kB 45.2 MB/s            \n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
      "     |████████████████████████████████| 192 kB 62.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from aiohttp>=3.7.1->s3fs) (3.10.0.2)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from aiohttp>=3.7.1->s3fs) (2.0.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from aiohttp>=3.7.1->s3fs) (21.2.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
      "     |████████████████████████████████| 160 kB 66.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from botocore<1.20.107,>=1.20.106->aiobotocore~=1.4.1->s3fs) (1.26.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from botocore<1.20.107,>=1.20.106->aiobotocore~=1.4.1->s3fs) (2.8.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from botocore<1.20.107,>=1.20.106->aiobotocore~=1.4.1->s3fs) (0.10.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp>=3.7.1->s3fs) (3.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.107,>=1.20.106->aiobotocore~=1.4.1->s3fs) (1.16.0)\n",
      "Building wheels for collected packages: aiobotocore\n",
      "  Building wheel for aiobotocore (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for aiobotocore: filename=aiobotocore-1.4.2-py3-none-any.whl size=49926 sha256=10f9aa43df01c000a8dfa57c55c1b9bdb315ee9428b52afe5c556cb0968eb52a\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/33/e7/d9/b297a9aa9c43d56bc2463e6e2771655ff638f30b30f0b61fcb\n",
      "Successfully built aiobotocore\n",
      "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, botocore, aioitertools, aiohttp, fsspec, aiobotocore, s3fs\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.23.5\n",
      "    Uninstalling botocore-1.23.5:\n",
      "      Successfully uninstalled botocore-1.23.5\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 0.8.3\n",
      "    Uninstalling fsspec-0.8.3:\n",
      "      Successfully uninstalled fsspec-0.8.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "boto3 1.20.5 requires botocore<1.24.0,>=1.23.5, but you have botocore 1.20.106 which is incompatible.\n",
      "awscli 1.22.5 requires botocore==1.23.5, but you have botocore 1.20.106 which is incompatible.\u001b[0m\n",
      "Successfully installed aiobotocore-1.4.2 aiohttp-3.8.1 aioitertools-0.8.0 aiosignal-1.2.0 async-timeout-4.0.1 asynctest-0.13.0 botocore-1.23.2 frozenlist-1.2.0 fsspec-2021.11.0 multidict-5.2.0 s3fs-2021.11.0 yarl-1.7.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "49f6a9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "11cd8aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.lambda_step import (\n",
    "    LambdaStep,\n",
    "    LambdaOutput,\n",
    "    LambdaOutputTypeEnum,\n",
    ")\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "role_arn = sagemaker.get_execution_role()\n",
    "default_bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a70e9088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://aws-ml-blog/artifacts/comprehend-custom-classification/comprehend-train.csv to ./comprehend-train.csv\n",
      "download: s3://aws-ml-blog/artifacts/comprehend-custom-classification/comprehend-test.csv to ./comprehend-test.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://aws-ml-blog/artifacts/comprehend-custom-classification/comprehend-train.csv s3://$default_bucket/\n",
    "!aws s3 cp s3://aws-ml-blog/artifacts/comprehend-custom-classification/comprehend-test.csv s3://$default_bucket/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419e602f",
   "metadata": {},
   "source": [
    "Next, we define parameters that can be set for the execution of the pipeline. They serve as variables. We define the following:\n",
    "\n",
    "- `ProcessingInstanceType`: The number of processing instances to use for the execution of the pipeline\n",
    "- `TrainData`: Location of the training data in S3\n",
    "- `TestData`: Location of the test data in S3\n",
    "- `RoleArn`: ARN (Amazon Resource Name) of the role used for pipeline execution\n",
    "- `ModelOutput`: Location of the target S3 path for the Amazon Comprehend model artifact\n",
    "\n",
    "Amazon Comprehend creates its own validation set when training, so there is no need to provide one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102ccc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting train and test files\n",
    "import pandas as pd\n",
    "\n",
    "trainFrame = pd.read_csv(f\"s3://aws-ml-blog/artifacts/comprehend-custom-classification/comprehend-train.csv\", header=None)\n",
    "trainFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146f9361",
   "metadata": {},
   "outputs": [],
   "source": [
    "testFrame = pd.read_csv(f\"s3://aws-ml-blog/artifacts/comprehend-custom-classification/comprehend-test.csv\", header=None)\n",
    "testFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3732fe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\", default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "\n",
    "input_train = ParameterString(\n",
    "    name=\"TrainData\",\n",
    "    default_value=f\"s3://{default_bucket}/comprehend-train.csv\",\n",
    ")\n",
    "\n",
    "input_test = ParameterString(\n",
    "    name=\"TestData\",\n",
    "    default_value=f\"s3://{default_bucket}/comprehend-test.csv\",\n",
    ")\n",
    "\n",
    "iam_role_arn = ParameterString(\n",
    "    name=\"RoleArn\",\n",
    "    default_value=role_arn,\n",
    ")\n",
    "\n",
    "model_output = ParameterString(name=\"ModelOutput\", default_value=f\"s3://{default_bucket}/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6004a5",
   "metadata": {},
   "source": [
    "We use [SKLearnProcessor](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html#sagemaker.sklearn.processing.SKLearnProcessor) to run Python scripts to train, and deploy Amazon Comprehend models using `boto3`. In the next chunk, we instantiate an instance of `SKLearnProcessor` that we use in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fbc41bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"comprehend-process\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role_arn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5212802",
   "metadata": {},
   "source": [
    "The first Amazon SageMaker [ProcessingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html?highlight=ProcessingStep#sagemaker.workflow.steps.ProcessingStep) provides a containerized execution environment to run the `prepare_data.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9ab8a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = ProcessingStep(\n",
    "    name=\"ComprehendProcess\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=input_train, destination=\"/opt/ml/processing/input_train\"),\n",
    "        ProcessingInput(source=input_test, destination=\"/opt/ml/processing/input_test\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    code=\"prepare_data.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7b5022",
   "metadata": {},
   "source": [
    "The second Amazon SageMaker processing step trains the Amazon Comprehend model by running `train_eval_comprehend.py`. Amazon Comprehend automatically evaluates the performance on an evaluation set. We will use that score as a condition for deploying the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d1672650",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_report = PropertyFile(\n",
    "    name=\"ComprehendEvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "61913acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehend_train_and_eval = ProcessingStep(\n",
    "    name=\"ComprehendTrainAndEval\",\n",
    "    processor=sklearn_processor,\n",
    "    job_arguments=[\n",
    "        \"--train-input-file\",\n",
    "        preprocess.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "        \"--train-output-path\",\n",
    "        model_output,\n",
    "        \"--iam-role-arn\",\n",
    "        role_arn,\n",
    "    ],\n",
    "    code=\"train_eval_comprehend.py\",\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "        ProcessingOutput(output_name=\"arn\", source=\"/opt/ml/processing/arn\"),\n",
    "    ],\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da32642c",
   "metadata": {},
   "source": [
    "The third Amazon SageMaker processing step deploys the Amazon Comprehend model running `deploy_comprehend.py`. If the Accuracy reported after training is lower than a certain threshold, this step does not run and the pipeline stops here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "790007b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_deploy_model = ProcessingStep(\n",
    "    name=\"ComprehendDeploy\",\n",
    "    processor=sklearn_processor,\n",
    "    job_arguments=[\n",
    "        \"--arn-path\",\n",
    "        comprehend_train_and_eval.properties.ProcessingOutputConfig.Outputs[\"arn\"].S3Output.S3Uri,\n",
    "    ],\n",
    "    code=\"deploy_comprehend.py\",\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"endpoint_arn\", source=\"/opt/ml/processing/endpoint_arn\")\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8ea704fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.workflow.properties.Properties at 0x7efecddf1590>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comprehend_train_and_eval.properties.ProcessingOutputConfig.Outputs[\"arn\"].S3Output.S3Uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a3607ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "cond_lte = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=\"ComprehendTrainAndEval\",\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"Accuracy\",\n",
    "    ),\n",
    "    right=0.65,\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=\"ComprehendAccuracyCondition\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_deploy_model],\n",
    "    else_steps=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12319d6",
   "metadata": {},
   "source": [
    "Finally, the deployed model can be used for inference. At this stage we use [AWS Lambda](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.lambda_step.LambdaStep) to call the Amazon Comprehend endpoint with the text of our choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cc864270",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = (\n",
    "    \"Italian EBU Member RAI has won the 65th Eurovision Song Contest with the song \"\n",
    "    + \"Zitti e buoni performed by Måneskin. It's the 3rd win for Italy who last triumphed in 1990. \"\n",
    "    + \"26 countries took part in the Grand Final of the world’s largest live music event, \"\n",
    "    + \"hosted by Dutch EBU Members NPO, NOS and AVROTROS on Saturday 22 May in Rotterdam. \"\n",
    "    + \"Måneskin wrote the winning song which finished the night with 524 points, 25 points \"\n",
    "    + \"ahead of 2nd placed France represented by Barbara Pravi singing Voila. Switzerland’s Gjon’s Tears with Tout l’Univers finished in third place.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e34fa27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Lambda Step\n",
    "function_name = \"sagemaker-lambda-step-endpoint-test\"\n",
    "\n",
    "# Lambda helper class can be used to create the Lambda function\n",
    "func = Lambda(\n",
    "    function_name=function_name,\n",
    "    session=sagemaker_session,\n",
    "    execution_role_arn=role_arn,\n",
    "    script=\"test_comprehend_lambda.py\",\n",
    "    handler=\"test_comprehend_lambda.lambda_handler\",\n",
    ")\n",
    "\n",
    "test_endpoint = LambdaStep(\n",
    "    name=\"LambdaStep\",\n",
    "    lambda_func=func,\n",
    "    inputs={\n",
    "        \"endpoint_arn_path\": step_deploy_model.properties.ProcessingOutputConfig.Outputs[\n",
    "            \"endpoint_arn\"\n",
    "        ].S3Output.S3Uri,\n",
    "        \"text\": example_text,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "55f8fe5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.workflow.properties.Properties at 0x7efecdde50d0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_deploy_model.properties.ProcessingOutputConfig.Outputs[\"endpoint_arn\"].S3Output.S3Uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "98fc98d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline_name = \"ComprehendPipeline\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_type,\n",
    "        processing_instance_count,\n",
    "        input_train,\n",
    "        input_test,\n",
    "        iam_role_arn,\n",
    "        model_output,\n",
    "    ],\n",
    "    steps=[preprocess, comprehend_train_and_eval, step_cond, test_endpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2064bc",
   "metadata": {},
   "source": [
    "Once the pipeline is successfully defined, we can start the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e1b55795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:eu-west-1:727118255515:pipeline/comprehendpipeline',\n",
       " 'ResponseMetadata': {'RequestId': '779a1921-3ced-4f47-98fe-561f5d599f43',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '779a1921-3ced-4f47-98fe-561f5d599f43',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '86',\n",
       "   'date': 'Thu, 25 Nov 2021 15:14:01 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dbc48827",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2e7d7589",
   "metadata": {},
   "outputs": [
    {
     "ename": "WaiterError",
     "evalue": "Waiter PipelineExecutionComplete failed: Waiter encountered a terminal failure state: For expression \"PipelineExecutionStatus\" we matched expected path: \"Failed\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWaiterError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-72be0c8b7085>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexecution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sagemaker/workflow/pipeline.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, delay, max_attempts)\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0mwaiter_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         )\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPipelineExecutionArn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/botocore/waiter.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mWaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     wait.__doc__ = WaiterDocstring(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/botocore/waiter.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                     \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                     \u001b[0mlast_response\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m                 )\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnum_attempts\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmax_attempts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWaiterError\u001b[0m: Waiter PipelineExecutionComplete failed: Waiter encountered a terminal failure state: For expression \"PipelineExecutionStatus\" we matched expected path: \"Failed\""
     ]
    }
   ],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89cbee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe22877",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bc4693",
   "metadata": {},
   "source": [
    "In this notebook we have seen how to create a SageMaker Pipeline to train an Amazon Comprehend Custom Classifier on your own dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5559a8",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "674cbfa9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'boto3' has no attribute 'delete_endpoint'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4d9f2e498fab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mboto3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_deploy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcessingOutputConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"arn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'boto3' has no attribute 'delete_endpoint'"
     ]
    }
   ],
   "source": [
    "pipeline.delete()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "sagemaker-examples",
   "language": "python",
   "name": "sagemaker-examples"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
